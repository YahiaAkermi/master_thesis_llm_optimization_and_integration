% Abstract
\vspace*{4cm}
\begin{center}
    {\Large\bf Abstract}
\end{center} \vskip 0.5cm \vskip 0.5cm
Large Language Models (LLMs) have revolutionized natural language processing, enabling a wide range of applications in enterprise environments. However, the integration of LLMs into enterprise systems presents unique challenges, particularly in selecting the most efficient communication protocol for deployment. This thesis investigates and compares three integration patterns—REST APIs, Message Control Protocols (MCP), and Streaming Protocols—focusing on their performance, scalability, and suitability for enterprise applications.

The study begins by exploring the architectural foundations of LLMs, including attention mechanisms and transformer-based models, to establish a technical context. It then evaluates the three integration patterns across key metrics such as latency, throughput, resource utilization, and adaptability to real-time and batch processing scenarios. The analysis is supported by experimental results derived from deploying LLMs in simulated enterprise environments.

This thesis also examines the trade-offs between protocol simplicity, parallelization capabilities, and real-time responsiveness, providing actionable insights for enterprise decision-makers. By synthesizing these findings, the research highlights best practices for optimizing LLM integration and offers a roadmap for future developments in enterprise AI systems.

\providecommand{\keywords}[1] {
  \small	
  \textbf{\textit{Keywords---}} #1
}
\keywords{Large Language Models, REST APIs, Message Control Protocols, Streaming Protocols, Enterprise Applications, Integration Patterns}
